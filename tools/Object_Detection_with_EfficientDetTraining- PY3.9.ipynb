{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bQO7jjVHckG"
      },
      "outputs": [],
      "source": [
        "# Install Miniconda\n",
        "!wget https://repo.anaconda.com/miniconda/Miniconda3-py37_4.9.2-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-py37_4.9.2-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-py37_4.9.2-Linux-x86_64.sh -b -f -p /usr/local\n",
        "\n",
        "# Update Conda\n",
        "!conda update -n base -c defaults conda -y\n",
        "\n",
        "# Create a Python 3.9 environment\n",
        "!conda create --name py39_environment python=3.9 -y\n",
        "\n",
        "# Initialize shell for Conda\n",
        "!conda init bash\n",
        "\n",
        "# Activate the environment and check Python version\n",
        "!source activate py39_environment && python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6T2jd1LLHr5O",
        "outputId": "f43bcb4e-16db-4f83-99a4-3009e3a5b7dd"
      },
      "outputs": [],
      "source": [
        "!source activate py39_environment && python --version\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install tflite_model_maker\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install -q pycocotools\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install opencv-python-headless\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip uninstall -y tensorflow && pip install -q tensorflow==2.8.0\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install ipykernel\n",
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && pip install --upgrade numba llvmlite\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXdz8hA7MqVN"
      },
      "outputs": [],
      "source": [
        "# For me dataset stays in app.roboflow.com :ie:\n",
        "!curl -L \"https://app.roboflow.com/ds/Sgx..........nlymZ\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jzt0EPAJNXGW"
      },
      "outputs": [],
      "source": [
        "# organize the dataset into dataset folder: \n",
        "!mkdir -p dataset/images\n",
        "!mkdir -p dataset/annotations\n",
        "\n",
        "!mv train/*.xml dataset/annotations/\n",
        "!mv train/*.jpg dataset/images/\n",
        "\n",
        "!mv test/*.xml dataset/annotations/\n",
        "!mv test/*.jpg dataset/images/\n",
        "\n",
        "!mv valid/*.xml dataset/annotations/\n",
        "!mv valid/*.jpg dataset/images/\n",
        "!rm -r test\n",
        "!rm -r train\n",
        "!rm -r valid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yYZ6PWfH891",
        "outputId": "168f42eb-45b1-4c3f-ea93-37d3daf89c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing my_script.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile my_script.py\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "np.object = object\n",
        "np.bool = bool\n",
        "np.complex = complex\n",
        "\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)\n",
        "\n",
        "use_custom_dataset = True\n",
        "dataset_is_split = False\n",
        "\n",
        "if use_custom_dataset:\n",
        "\n",
        "  # The ZIP file you uploaded:\n",
        "  #!unzip dataset.zip\n",
        "\n",
        "  # Your labels map as a dictionary (zero is reserved):\n",
        "  label_map = {1: 'YM'}\n",
        "  print(label_map)\n",
        "\n",
        "  if dataset_is_split:\n",
        "    # If your dataset is already split, specify each path:\n",
        "    train_images_dir = 'dataset/train/images'\n",
        "    train_annotations_dir = 'dataset/train/annotations'\n",
        "    val_images_dir = 'dataset/validation/images'\n",
        "    val_annotations_dir = 'dataset/validation/annotations'\n",
        "    test_images_dir = 'dataset/test/images'\n",
        "    test_annotations_dir = 'dataset/test/annotations'\n",
        "  else:\n",
        "    # If it's NOT split yet, specify the path to all images and annotations\n",
        "    images_in = 'dataset/images'\n",
        "    annotations_in = 'dataset/annotations'\n",
        "\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "def split_dataset(images_path, annotations_path, val_split, test_split, out_path):\n",
        "  \"\"\"Splits a directory of sorted images/annotations into training, validation, and test sets.\n",
        "\n",
        "  Args:\n",
        "    images_path: Path to the directory with your images (JPGs).\n",
        "    annotations_path: Path to a directory with your VOC XML annotation files,\n",
        "      with filenames corresponding to image filenames. This may be the same path\n",
        "      used for images_path.\n",
        "    val_split: Fraction of data to reserve for validation (float between 0 and 1).\n",
        "    test_split: Fraction of data to reserve for test (float between 0 and 1).\n",
        "  Returns:\n",
        "    The paths for the split images/annotations (train_dir, val_dir, test_dir)\n",
        "  \"\"\"\n",
        "  _, dirs, _ = next(os.walk(images_path))\n",
        "\n",
        "  train_dir = os.path.join(out_path, 'train')\n",
        "  val_dir = os.path.join(out_path, 'validation')\n",
        "  test_dir = os.path.join(out_path, 'test')\n",
        "\n",
        "  IMAGES_TRAIN_DIR = os.path.join(train_dir, 'images')\n",
        "  IMAGES_VAL_DIR = os.path.join(val_dir, 'images')\n",
        "  IMAGES_TEST_DIR = os.path.join(test_dir, 'images')\n",
        "  os.makedirs(IMAGES_TRAIN_DIR, exist_ok=True)\n",
        "  os.makedirs(IMAGES_VAL_DIR, exist_ok=True)\n",
        "  os.makedirs(IMAGES_TEST_DIR, exist_ok=True)\n",
        "\n",
        "  ANNOT_TRAIN_DIR = os.path.join(train_dir, 'annotations')\n",
        "  ANNOT_VAL_DIR = os.path.join(val_dir, 'annotations')\n",
        "  ANNOT_TEST_DIR = os.path.join(test_dir, 'annotations')\n",
        "  os.makedirs(ANNOT_TRAIN_DIR, exist_ok=True)\n",
        "  os.makedirs(ANNOT_VAL_DIR, exist_ok=True)\n",
        "  os.makedirs(ANNOT_TEST_DIR, exist_ok=True)\n",
        "\n",
        "  # Get all filenames for this dir, filtered by filetype\n",
        "  filenames = os.listdir(os.path.join(images_path))\n",
        "  filenames = [os.path.join(images_path, f) for f in filenames if (f.endswith('.jpg'))]\n",
        "  # Shuffle the files, deterministically\n",
        "  filenames.sort()\n",
        "  random.seed(42)\n",
        "  random.shuffle(filenames)\n",
        "  # Get exact number of images for validation and test; the rest is for training\n",
        "  val_count = int(len(filenames) * val_split)\n",
        "  test_count = int(len(filenames) * test_split)\n",
        "  for i, file in enumerate(filenames):\n",
        "    source_dir, filename = os.path.split(file)\n",
        "    annot_file = os.path.join(annotations_path, filename.replace(\".jpg\", \".xml\"))\n",
        "    if i < val_count:\n",
        "      shutil.copy(file, IMAGES_VAL_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_VAL_DIR)\n",
        "    elif i < val_count + test_count:\n",
        "      shutil.copy(file, IMAGES_TEST_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_TEST_DIR)\n",
        "    else:\n",
        "      shutil.copy(file, IMAGES_TRAIN_DIR)\n",
        "      shutil.copy(annot_file, ANNOT_TRAIN_DIR)\n",
        "  return (train_dir, val_dir, test_dir)\n",
        "\n",
        "# We need to instantiate a separate DataLoader for each split dataset\n",
        "if use_custom_dataset:\n",
        "  if dataset_is_split:\n",
        "    train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        train_images_dir, train_annotations_dir, label_map=label_map)\n",
        "    validation_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        val_images_dir, val_annotations_dir, label_map=label_map)\n",
        "    test_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        test_images_dir, test_annotations_dir, label_map=label_map)\n",
        "  else:\n",
        "    train_dir, val_dir, test_dir = split_dataset(images_in, annotations_in,\n",
        "                                                 val_split=0.2, test_split=0.2,\n",
        "                                                 out_path='split-dataset')\n",
        "    train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        os.path.join(train_dir, 'images'),\n",
        "        os.path.join(train_dir, 'annotations'), label_map=label_map)\n",
        "    validation_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        os.path.join(val_dir, 'images'),\n",
        "        os.path.join(val_dir, 'annotations'), label_map=label_map)\n",
        "    test_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        os.path.join(test_dir, 'images'),\n",
        "        os.path.join(test_dir, 'annotations'), label_map=label_map)\n",
        "\n",
        "  print(f'train count: {len(train_data)}')\n",
        "  print(f'validation count: {len(validation_data)}')\n",
        "  print(f'test count: {len(test_data)}')\n",
        "\n",
        "\n",
        "spec = model_spec.get('efficientdet_lite2')\n",
        "\n",
        "model = object_detector.create(train_data=train_data,\n",
        "                               model_spec=spec,\n",
        "                               validation_data=validation_data,\n",
        "                               epochs=150,\n",
        "                               batch_size=10,\n",
        "                               train_whole_model=True)\n",
        "\n",
        "TFLITE_FILENAME = 'model-effi_02-v4.tflite'\n",
        "LABELS_FILENAME = 'labels.txt'\n",
        "\n",
        "model.export(export_dir='.', tflite_filename=TFLITE_FILENAME, label_filename=LABELS_FILENAME,\n",
        "             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])\n",
        "\n",
        "model.evaluate(test_data)\n",
        "\n",
        "model.evaluate_tflite(TFLITE_FILENAME, test_data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRXOiK3xMpPb",
        "outputId": "a0b050c6-cd59-4d0f-eec0-ec19630f1256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/envs/py39_environment/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/envs/py39_environment/lib/python3.9/site-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.11.0 and strictly below 2.14.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  warnings.warn(\n",
            "{1: 'YM'}\n",
            "train count: 1090\n",
            "validation count: 362\n",
            "test count: 362\n",
            "2023-10-01 09:26:13.247847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:13.792096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:13.792481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:13.793185: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-01 09:26:13.793505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:13.793761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:13.793980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:14.476591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:14.477084: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:14.477410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-10-01 09:26:14.477595: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2023-10-01 09:26:14.477747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13786 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Epoch 1/150\n",
            "2023-10-01 09:27:13.348057: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 32112640 exceeds 10% of free system memory.\n",
            "2023-10-01 09:27:13.785254: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 32112640 exceeds 10% of free system memory.\n",
            "2023-10-01 09:27:13.785333: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 32112640 exceeds 10% of free system memory.\n",
            "2023-10-01 09:27:13.798951: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 32112640 exceeds 10% of free system memory.\n",
            "2023-10-01 09:27:17.124548: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 32112640 exceeds 10% of free system memory.\n",
            "2023-10-01 09:27:21.775702: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8900\n",
            "109/109 [==============================] - 136s 734ms/step - det_loss: 1.8764 - cls_loss: 0.9147 - box_loss: 0.0192 - reg_l2_loss: 0.0762 - loss: 1.9526 - learning_rate: 0.0102 - gradient_norm: 6.4334 - val_det_loss: 1.7758 - val_cls_loss: 0.9469 - val_box_loss: 0.0166 - val_reg_l2_loss: 0.0768 - val_loss: 1.8526\n",
            "Epoch 2/150\n",
            "109/109 [==============================] - 81s 745ms/step - det_loss: 1.3576 - cls_loss: 0.6283 - box_loss: 0.0146 - reg_l2_loss: 0.0775 - loss: 1.4351 - learning_rate: 0.0125 - gradient_norm: 5.8348 - val_det_loss: 1.8362 - val_cls_loss: 0.9649 - val_box_loss: 0.0174 - val_reg_l2_loss: 0.0779 - val_loss: 1.9142\n",
            "Epoch 3/150\n",
            "109/109 [==============================] - 77s 703ms/step - det_loss: 1.2033 - cls_loss: 0.5845 - box_loss: 0.0124 - reg_l2_loss: 0.0783 - loss: 1.2816 - learning_rate: 0.0125 - gradient_norm: 5.0853 - val_det_loss: 1.6087 - val_cls_loss: 0.8795 - val_box_loss: 0.0146 - val_reg_l2_loss: 0.0787 - val_loss: 1.6874\n",
            "Epoch 4/150\n",
            "109/109 [==============================] - 82s 752ms/step - det_loss: 1.0891 - cls_loss: 0.5241 - box_loss: 0.0113 - reg_l2_loss: 0.0790 - loss: 1.1681 - learning_rate: 0.0125 - gradient_norm: 4.4115 - val_det_loss: 1.3068 - val_cls_loss: 0.6820 - val_box_loss: 0.0125 - val_reg_l2_loss: 0.0793 - val_loss: 1.3861\n",
            "Epoch 5/150\n",
            "109/109 [==============================] - 98s 902ms/step - det_loss: 1.0752 - cls_loss: 0.5219 - box_loss: 0.0111 - reg_l2_loss: 0.0795 - loss: 1.1548 - learning_rate: 0.0125 - gradient_norm: 4.1959 - val_det_loss: 1.2252 - val_cls_loss: 0.5724 - val_box_loss: 0.0131 - val_reg_l2_loss: 0.0798 - val_loss: 1.3050\n",
            "Epoch 6/150\n",
            " 67/109 [=================>............] - ETA: 25s - det_loss: 0.9829 - cls_loss: 0.4763 - box_loss: 0.0101 - reg_l2_loss: 0.0799 - loss: 1.0628 - learning_rate: 0.0125 - gradient_norm: 3.8965"
          ]
        }
      ],
      "source": [
        "!source /usr/local/etc/profile.d/conda.sh && conda activate py39_environment && python my_script.py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j499kiW4SbX"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "! sudo apt-get update\n",
        "\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-ZAJhSe4tH3",
        "outputId": "786d0fe4-156d-475d-99fb-e85065fde1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Edge TPU Compiler version 16.0.384591198\n",
            "Searching for valid delegate with step 1\n",
            "Try to compile segment with 357 ops\n",
            "Started a compilation timeout timer of 180 seconds.\n",
            "\n",
            "Model compiled successfully in 19550 ms.\n",
            "\n",
            "Input model: x-ray-effi0-v4.tflite\n",
            "Input size: 7.05MiB\n",
            "Output model: x-ray-effi0-v4_edgetpu.tflite\n",
            "Output size: 9.74MiB\n",
            "On-chip memory used for caching model parameters: 7.14MiB\n",
            "On-chip memory remaining for caching model parameters: 1.25KiB\n",
            "Off-chip memory used for streaming uncached model parameters: 228.88KiB\n",
            "Number of Edge TPU subgraphs: 1\n",
            "Total number of operations: 357\n",
            "Operation log: x-ray-effi0-v4_edgetpu.log\n",
            "\n",
            "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\n",
            "Number of operations that will run on Edge TPU: 354\n",
            "Number of operations that will run on CPU: 3\n",
            "See the operation log file for individual operation details.\n",
            "Compilation child process completed within timeout period.\n",
            "Compilation succeeded! \n"
          ]
        }
      ],
      "source": [
        "%%shell\n",
        "NUMBER_OF_TPUS =  1\n",
        "TFLITE_FILENAME = 'model-effi_02-v4.tflite'\n",
        "LABELS_FILENAME = 'labels.txt'\n",
        "edgetpu_compiler $TFLITE_FILENAME -d --num_segments=$NUMBER_OF_TPUS"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
